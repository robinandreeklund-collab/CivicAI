# CivicAI Project Configuration
# Configuration file for OneSeek-7B-Zero training and model management

# Project Information
project:
  name: "CivicAI"
  version: "1.0.0"
  description: "Adaptive training system for OneSeek-7B-Zero with DNA v2 fingerprinting"

# Base Models Configuration
# These models are selected from the admin panel and should NOT be hardcoded with defaults
# The training system will ONLY use models explicitly selected by administrators
base_models:
  # Selected models will be populated from admin panel selection
  # Examples: mistral-7b-instruct, llama-2-7b-chat, gpt-sw3-20b-instruct
  selected: []
  
  # Discovery settings
  discovery:
    enabled: true
    search_paths:
      - "models/"
      - "models/base_models/"
    
  # Validation settings
  validation:
    require_config_json: true
    require_tokenizer: true

# Training Configuration
training:
  # Default training parameters (can be overridden via CLI or admin panel)
  defaults:
    epochs: 3
    batch_size: 8
    learning_rate: 0.0001
    seed: 42
    language: "en"
  
  # Adaptive Training Weights Engine
  adaptive_weights:
    enabled: true
    
    # Weight multiplier bounds
    min_multiplier: 0.5    # Bottom model gets at least 50% weight
    max_multiplier: 1.5    # Top model gets at most 150% weight
    
    # Adjustment strategy
    adjust_strategy:
      # How to adjust weights based on performance
      top_model_boost: 0.3      # +30% for best performing model
      bottom_model_penalty: 0.4  # -40% for worst performing model
      
      # Normalization
      normalize_weights: true    # Always normalize to sum=1.0
      
      # Frequency of adjustments
      adjust_every_epoch: true
  
  # Live Leaderboard Configuration
  live_leaderboard:
    enabled: true
    refresh_interval: 5  # seconds - how often to broadcast updates
    
    # Display settings
    display:
      show_weights: true
      show_lr_multipliers: true
      show_loss_per_model: true
      show_progress: true
  
  # Confidence-Based Auto-Stop
  confidence_auto_stop:
    enabled: true
    threshold: 0.001      # Stop if loss change < 0.001
    patience: 3           # Over 3 consecutive epochs
    
    # Minimum epochs before auto-stop can trigger
    min_epochs: 2
  
  # Live Metrics to Broadcast
  live_metrics_to_broadcast:
    - "epoch"
    - "val_losses"           # Per-model validation losses
    - "weights"              # Current adaptive weights per model
    - "lr_multipliers"       # Learning rate multipliers per model
    - "total_loss"           # Combined validation loss
    - "auto_stop_info"       # Remaining patience, threshold status
    - "progress_percent"     # Overall training progress
    - "current_lr"           # Current learning rate

# Model Management
models:
  # Output directory for certified models
  output_dir: "models/oneseek-certified"
  
  # Metadata configuration
  metadata:
    # File naming (NO COLONS - use hyphens or underscores)
    naming_pattern: "run-{timestamp}"  # e.g., run-20231122-143025
    timestamp_format: "%Y%m%d-%H%M%S"
    
    # Atomic writes for metadata files
    use_atomic_writes: true
    temp_suffix: ".tmp"
    
    # Metadata versioning
    version: "2.0"
    include_immutable_hash: true
  
  # DNA Fingerprint Configuration
  dna:
    version: "2.0"
    format: "OneSeek-7B-Zero.v{version}.{category_hash}"
    include_dataset_categories: true
    include_base_model_weights: true

# API Configuration
api:
  # Training Metrics Endpoint
  training_metrics:
    enabled: true
    endpoint_pattern: "/api/training/{run_id}/metrics"
    
    # Cache settings
    cache_enabled: true
    cache_ttl: 5  # seconds
  
  # WebSocket Configuration
  websocket:
    enabled: true
    endpoint_pattern: "/ws/training/{run_id}"
    
    # Event types
    events:
      - "epoch_start"
      - "epoch_end"
      - "weight_adjustment"
      - "auto_stop_triggered"
      - "training_complete"
      - "training_error"
    
    # Connection settings
    heartbeat_interval: 30  # seconds
    max_connections_per_run: 10

# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  
  # Log outputs
  outputs:
    console: true
    file: true
    
  # Log file settings
  file:
    path: "logs/training.log"
    max_size_mb: 100
    max_files: 10
    
  # Structured logging
  format: "json"
  include_timestamps: true
  include_context: true

# Storage Configuration
storage:
  # Dataset storage
  datasets_dir: "datasets"
  
  # Training history
  history_file: "ml/training_history.json"
  max_history_entries: 50
  
  # Ledger configuration
  ledger:
    enabled: true
    dir: "ml/ledger"
    type: "in_memory"  # or "http" for remote ledger

# Security Configuration
security:
  # Authentication
  require_admin_auth: true
  
  # Rate limiting
  rate_limiting:
    enabled: true
    max_requests_per_minute: 60
  
  # Input validation
  validation:
    max_dataset_size_mb: 100
    allowed_file_extensions: [".json", ".jsonl"]

# Performance Configuration
performance:
  # CPU/GPU settings
  device:
    auto_detect: true
    fallback_to_cpu: true
  
  # Memory management
  memory:
    max_batch_size: 64
    gradient_accumulation_steps: 1
  
  # Monitoring
  monitoring:
    enabled: true
    interval: 10  # seconds
    metrics:
      - "cpu_percent"
      - "memory_percent"
      - "disk_io"

# Environment Configuration
environment:
  # Development/Production mode
  mode: "development"  # or "production"
  
  # Feature flags
  features:
    enable_experimental: false
    enable_debug_mode: false
    enable_profiling: false
