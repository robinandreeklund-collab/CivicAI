# OQT-1.0 Multi-Model Integration

This implementation extends OQT-1.0 (Open Quality Transformer) with multi-model architecture using **Mistral 7B** and **LLaMA-2** as foundational models.

## ğŸ¯ Features

### Multi-Model Architecture
- **Mistral 7B**: Fast, analytical responses with efficient inference
- **LLaMA-2 7B/13B**: Deep, comprehensive analysis with nuanced reasoning
- **Optional External Models**: GPT-3.5, Gemini, Grok for comparison

### Analysis Pipeline
- **Consensus Analysis**: Calculate agreement between model outputs
- **Cross-Model Bias Detection**: Aggregate bias scores across responses
- **Fairness Index**: Assess fairness and inclusivity of responses
- **Meta-Summary Generation**: Synthesize insights from all models

### Real-Time Microtraining
**Two-Step Process:**
1. **Stage 1**: Train on raw AI responses
2. **Stage 2**: Train on pipeline-analyzed data (consensus, bias, fairness)

### Dashboard Integration
- Query interface at `/oqt-dashboard`
- Display synthesized OQT responses
- Visualize consensus, bias, and fairness metrics
- Show model comparison data
- Real-time training feedback

## ğŸš€ Quick Start

### 1. Start the Backend
```bash
cd backend
npm install
npm run dev
```

Backend will start on `http://localhost:3001`

### 2. Start the Frontend
```bash
cd frontend
npm install
npm run dev
```

Frontend will start on `http://localhost:3000`

### 3. Access OQT Dashboard
Navigate to: `http://localhost:3000/oqt-dashboard`

## ğŸ“¡ API Usage

### Multi-Model Query
```bash
curl -X POST http://localhost:3001/api/oqt/multi-model-query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Hur pÃ¥verkar AI samhÃ¤llet?",
    "includeExternal": false,
    "enableTraining": true
  }'
```

### Get Model Status
```bash
curl http://localhost:3001/api/oqt/status
```

### Get Model Metrics
```bash
curl http://localhost:3001/api/oqt/metrics
```

## ğŸ§ª Testing

Run the comprehensive test suite:
```bash
cd backend
npm test -- oqtMultiModel.test.js
```

**Test Coverage:**
- Mistral service (3 tests)
- LLaMA service (3 tests)
- Multi-model pipeline (6 tests)
- Integration tests (2 tests)
- **Total: 14 tests âœ…**

## ğŸ“Š Example Output

```json
{
  "success": true,
  "model": "OQT-1.0",
  "version": "1.2.0",
  "response": "OQT-1.0 Syntetiserat Svar...",
  "confidence": 0.92,
  "analysis": {
    "consensus": {
      "score": 0.95,
      "level": "high"
    },
    "bias": {
      "aggregatedScore": 0,
      "level": "low"
    },
    "fairness": {
      "score": 0.88,
      "level": "excellent"
    }
  },
  "training": {
    "stage1": { "samplesProcessed": 2 },
    "stage2": { "metricsUpdated": true }
  }
}
```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ oqt.js                    # OQT API endpoints (enhanced)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ mistral.js                # Mistral 7B integration
â”‚   â”œâ”€â”€ llama.js                  # LLaMA-2 integration
â”‚   â”œâ”€â”€ oqtMultiModelPipeline.js  # Multi-model orchestration
â”‚   â”œâ”€â”€ analysisPipeline.js       # Analysis pipeline (existing)
â”‚   â””â”€â”€ ...
â””â”€â”€ tests/
    â””â”€â”€ oqtMultiModel.test.js     # Comprehensive tests

frontend/
â””â”€â”€ src/
    â””â”€â”€ pages/
        â””â”€â”€ OQTDashboardPage.jsx   # Enhanced with query interface

docs/
â””â”€â”€ OQT_MULTI_MODEL_API.md        # Complete API documentation

examples/
â””â”€â”€ oqt-multi-model-example.js    # Usage example script
```

## ğŸ”§ Configuration

### Environment Variables (Optional)

```bash
# Backend API Base URL
API_BASE=http://localhost:3001

# External AI APIs (optional, uses simulated responses if not set)
OPENAI_API_KEY=your_key_here
GEMINI_API_KEY=your_key_here
XAI_API_KEY=your_key_here
```

### Model Options

When querying, you can configure:
- `includeExternal`: Add GPT, Gemini, Grok for comparison
- `enableTraining`: Perform real-time microtraining
- `temperature`: Adjust response creativity (0.0 - 1.0)

## ğŸ“ˆ Performance

- **Average Pipeline Time**: ~300ms
- **Models Processed**: 2-5 (depending on configuration)
- **Consensus Calculation**: <10ms
- **Bias Detection**: <20ms per model
- **Fairness Assessment**: <15ms

## ğŸ¨ Dashboard Features

### Query Tab
- Text input for questions
- Real-time processing indicator
- Synthesized OQT response display
- Confidence score

### Analysis Metrics
- **Consensus Card**: Score, level, sentiment/tone agreement
- **Bias Card**: Aggregated score, level, detected bias types
- **Fairness Card**: Score, level indicator

### Model Responses
- Preview of each model's response
- Latency metrics
- Model identification

### Training Info
- Stage 1 & 2 status
- Samples processed
- Total microtraining sessions

### Meta Summary
- Recommendation based on analysis
- Key themes extraction
- Overall assessment

## ğŸ”® Future Enhancements

1. **Advanced Visualizations**
   - Consensus heatmap
   - Bias radar chart
   - Community trends timeline

2. **Model Expansion**
   - Domain-specific models
   - Multimodal support
   - Custom model integration

3. **Training Improvements**
   - Weekly batch automation
   - Adaptive learning rate
   - Model versioning system

4. **Analytics**
   - Query history tracking
   - Trend analysis
   - Performance monitoring

## ğŸ“š Documentation

- **API Documentation**: [docs/OQT_MULTI_MODEL_API.md](./docs/OQT_MULTI_MODEL_API.md)
- **Architecture**: See API docs for pipeline diagram
- **Examples**: [examples/oqt-multi-model-example.js](./examples/oqt-multi-model-example.js)

## ğŸ¤ Contributing

This implementation builds on PR #55. For contributions:
1. Review the API documentation
2. Run tests to ensure compatibility
3. Follow existing code patterns
4. Update documentation as needed

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- Built on top of PR #55: OQT-1.0 Integration
- Uses Mistral AI and Meta's LLaMA-2 architectures
- Integrated with existing OneSeek.AI analysis pipeline

---

**Version**: 2.0  
**Last Updated**: November 2025  
**Status**: Production Ready âœ…
