# Python Dependencies for OQT-1.0
# Complete requirements for running Mistral 7B and LLaMA-2 locally

# Deep Learning Framework
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0

# Transformers and Model Loading
transformers>=4.35.0
accelerate>=0.24.0
sentencepiece>=0.1.99
tokenizers>=0.15.0
safetensors>=0.4.0

# Model Optimization
bitsandbytes>=0.41.0  # 8-bit quantization
optimum>=1.14.0  # Hardware optimization
auto-gptq>=0.5.0  # GPTQ quantization (optional)

# Firebase Integration
firebase-admin>=6.2.0
google-cloud-firestore>=2.13.0
google-cloud-storage>=2.10.0

# Web Frameworks
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
flask>=3.0.0
flask-cors>=4.0.0
pydantic>=2.5.0

# ML Pipeline and NLP
scikit-learn>=1.3.0
numpy>=1.24.0
pandas>=2.1.0
scipy>=1.11.0

# Text Processing
nltk>=3.8.1
spacy>=3.7.0
langdetect>=1.0.9
textblob>=0.17.1

# Bias and Fairness Detection
detoxify>=0.5.2
fairlearn>=0.10.0

# Explainability
shap>=0.43.0
lime>=0.2.0.1

# Topic Modeling
bertopic>=0.15.0
umap-learn>=0.5.4

# API and HTTP
requests>=2.31.0
httpx>=0.25.0
aiohttp>=3.9.0

# Data Validation and Parsing
pyyaml>=6.0.1
python-dotenv>=1.0.0
python-multipart>=0.0.6

# Monitoring and Logging
prometheus-client>=0.19.0
python-json-logger>=2.0.7

# Utilities
tqdm>=4.66.0
click>=8.1.7
colorama>=0.4.6

# Testing (optional but recommended)
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0

# GPU Acceleration (optional, install separately if needed)
# nvidia-cuda-runtime-cu11>=11.8.89
# nvidia-cudnn-cu11>=8.9.0

# Optional: Additional Model Support
# xformers>=0.0.22  # Memory-efficient attention
# flash-attn>=2.3.0  # Flash attention (requires compatible GPU)
