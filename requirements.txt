# Python Dependencies for OQT-1.0
# Complete requirements for running Mistral 7B and LLaMA-2 locally
#
# INSTALLATION ORDER:
# 1. Install PyTorch first (requires specific version for your hardware)
# 2. (Optional) Install GPU acceleration
# 3. Install this requirements file
#
# ===== STEP 1: PyTorch Installation =====
#
# For NVIDIA GPU (CUDA 11.8):
#   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
#
# For CPU only:
#   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
#
# ===== STEP 2: GPU Acceleration (Optional but recommended) =====
#
# For Windows with Intel GPU (DirectML):
#   pip install torch-directml
#
# For Linux with Intel GPU (IPEX):
#   pip install intel-extension-for-pytorch
#   pip install oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/
#
# ===== STEP 3: Install requirements =====
#   pip install -r requirements.txt
#
# See PYTHON_INSTALL_GUIDE.md and INTEL_GPU_OPTIMIZATION.md for detailed instructions


# Core Python packages
numpy>=1.24.0,<2.0.0
pyyaml>=6.0.1
python-dotenv>=1.0.0
requests>=2.31.0
tqdm>=4.66.0
click>=8.1.7
colorama>=0.4.6

# Deep Learning Framework (install separately first - see above)
# torch>=2.0.0
# torchvision>=0.15.0
# torchaudio>=2.0.0

# Transformers and Model Loading (requires torch)
transformers>=4.35.0
accelerate>=0.24.0
sentencepiece>=0.1.99
tokenizers>=0.15.0
safetensors>=0.4.0

# Model Optimization (requires torch, install after transformers)
# Note: bitsandbytes may not work on Windows or require special setup
# bitsandbytes>=0.41.0  # 8-bit quantization - OPTIONAL, GPU only
optimum>=1.14.0  # Hardware optimization
# auto-gptq>=0.5.0  # GPTQ quantization - OPTIONAL, advanced users only

# Firebase Integration
firebase-admin>=6.2.0
google-cloud-firestore>=2.13.0
google-cloud-storage>=2.10.0

# Web Frameworks
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
flask>=3.0.0
flask-cors>=4.0.0
pydantic>=2.5.0

# ML Pipeline and NLP
scikit-learn>=1.3.0
pandas>=2.1.0
scipy>=1.11.0

# Text Processing
nltk>=3.8.1
spacy>=3.7.0
langdetect>=1.0.9
textblob>=0.17.1

# Bias and Fairness Detection
detoxify>=0.5.2
fairlearn>=0.10.0

# Explainability
shap>=0.43.0
lime>=0.2.0.1

# Topic Modeling
# Note: BERTopic has many dependencies, install separately if needed
# bertopic>=0.15.0
# umap-learn>=0.5.4

# API and HTTP
requests>=2.31.0
httpx>=0.25.0
aiohttp>=3.9.0

# Data Validation and Parsing
pyyaml>=6.0.1
python-dotenv>=1.0.0
python-multipart>=0.0.6

# Monitoring and Logging
prometheus-client>=0.19.0
python-json-logger>=2.0.7

# Utilities
tqdm>=4.66.0
click>=8.1.7
colorama>=0.4.6

# Testing (optional but recommended)
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0

# GPU Acceleration (optional, install separately if needed)
# nvidia-cuda-runtime-cu11>=11.8.89
# nvidia-cudnn-cu11>=8.9.0

# Optional: Additional Model Support
# xformers>=0.0.22  # Memory-efficient attention
# flash-attn>=2.3.0  # Flash attention (requires compatible GPU)
