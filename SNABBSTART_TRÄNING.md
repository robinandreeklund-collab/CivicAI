# Snabbstart: Tr√§na OneSeek-7B-Zero med Identity Dataset

Detta dokument ger steg-f√∂r-steg instruktioner f√∂r att komma ig√•ng med att tr√§na OneSeek-7B-Zero p√• identity-dataset s√• att modellen l√§r sig sin identitet som OpenSeek AI-agent.

## üéØ M√•l

Tr√§na OneSeek-7B-Zero att f√∂rst√•:
- Vem den √§r (OpenSeek AI-agent)
- Vad den g√∂r (transparent AI-analys med multi-modell konsensus)
- Hur den fungerar (Mistral 7B + LLaMA-2, LoRA/PEFT, ledger-transparens)
- Sina etiska principer (r√§ttvisa, transparens, ansvarsskyldighet)

## üìã F√∂rberedelser

### Steg 1: Verifiera att allt √§r installerat

```bash
# Kontrollera att du √§r i r√§tt directory
cd /path/to/CivicAI

# Kontrollera att identity dataset finns
ls -la datasets/oneseek_identity_v1.jsonl

# Output ska visa: 50 rader (exempel) i JSONL-format
```

### Steg 2: Installera Python-beroenden

```bash
# Skapa virtual environment (om du inte redan har ett)
python3 -m venv venv
source venv/bin/activate  # P√• Windows: venv\Scripts\activate

# Installera beroenden
pip install -r ml/requirements.txt

# Eller installera manuellt:
pip install numpy pandas scikit-learn
```

## üöÄ Metod 1: Enkel Snabbstart (Rekommenderad f√∂r f√∂rsta g√•ngen)

Detta √§r det enklaste s√§ttet att komma ig√•ng. Skriptet hanterar allt automatiskt.

### K√∂r tr√§ningsskriptet:

```bash
# Fr√•n repository root
python scripts/train_identity.py
```

**Vad h√§nder:**
1. ‚úÖ Skriptet verifierar att identity dataset finns (50 exempel)
2. üì¶ Konverterar JSONL till tr√§ningsformat
3. üîÑ Delar upp i train/validation (90/10)
4. üíæ Sparar till `ml/data/prepared/`
5. üöÄ K√∂r tr√§ningspipeline
6. üìä Skapar modellversion med metadata
7. üìù Loggar till transparency ledger

**Output:**
```
======================================================================
  OneSeek-7B-Zero Identity Training - Quick Start
======================================================================

‚úÖ Found identity dataset: 50 examples
   Location: datasets/oneseek_identity_v1.jsonl

üì¶ Preparing training data...
‚úÖ Training data prepared:
   - Training samples: 45
   - Validation samples: 5

üöÄ Starting training...

======================================================================
Training OneSeek-7B-Zero Version 1.0
======================================================================

Dataset sizes:
  Training: 45
  Validation: 5

Training configuration:
  model_name: OneSeek-7B-Zero
  base_models: ['Mistral-7B', 'LLaMA-2']
  use_lora: True
  lora_rank: 8

Training completed!

Final Metrics:
  validation_accuracy: 0.876
  fairness_score: 0.912

‚úÖ Training completed successfully!
```

## üîß Metod 2: Manuell Tr√§ning (F√∂r avancerade anv√§ndare)

Om du vill ha full kontroll √∂ver tr√§ningsprocessen:

### Steg 1: F√∂rbered dataset

```bash
# Konvertera identity dataset till tr√§ningsformat
cd ml/pipelines
python prepare_dataset.py --identity-only
```

### Steg 2: K√∂r tr√§ning

```bash
cd ml/training
python train_language_model.py --version 1.0
```

### Steg 3: Verifiera resultat

```bash
# Kontrollera att modellfilerna skapades
ls -la models/oneseek-7b-zero/weights/

# Du b√∂r se:
# - oneseek-7b-zero-v1.0.json (metadata)
# - oneseek-7b-zero-v1.0.pth (vikter - skapas n√§r PyTorch √§r installerat)
```

## üìä Vad h√§nder under tr√§ningen?

### 1. Dataset-konvertering

Identity dataset (JSONL):
```json
{
  "instruction": "Vem √§r du?",
  "input": "",
  "output": "Jag √§r OpenSeek AI-agent..."
}
```

Blir till tr√§ningsformat:
```json
{
  "id": "identity_0",
  "question": "Vem √§r du?",
  "responses": [{
    "model": "OneSeek-Identity",
    "response_text": "Jag √§r OpenSeek AI-agent..."
  }],
  "analysis": {
    "consensus_score": 1.0
  }
}
```

### 2. Tr√§ningsprocessen

```
[Dataset] ‚Üí [Preprocessing] ‚Üí [Model Training] ‚Üí [Validation] ‚Üí [Save]
   ‚Üì              ‚Üì                   ‚Üì              ‚Üì           ‚Üì
  50           45 train          LoRA/PEFT      Metrics    v1.0.json
examples      5 val              adapters       0.876       v1.0.pth
```

### 3. Resultat som sparas

**Metadata** (`oneseek-7b-zero-v1.0.json`):
```json
{
  "version": "1.0",
  "model_name": "OneSeek-7B-Zero",
  "base_models": ["Mistral-7B", "LLaMA-2"],
  "training_config": {
    "dataset_size": 45,
    "use_lora": true,
    "lora_rank": 8
  },
  "metrics": {
    "validation_accuracy": 0.876,
    "fairness_score": 0.912
  },
  "provenance": {
    "training_data_hash": "sha256:...",
    "ledger_block_id": "block-1",
    "trainer": "OneSeek-Training-Pipeline"
  }
}
```

**Vikter** (`oneseek-7b-zero-v1.0.pth`):
- Skapas n√§r PyTorch √§r installerat
- Inneh√•ller LoRA adapter-vikter
- Storlek: ~50-100 MB (LoRA √§r parameter-effektiv!)

## ‚úÖ Verifiera att tr√§ningen lyckades

### 1. Kontrollera filer

```bash
# Modellmetadata
cat models/oneseek-7b-zero/weights/oneseek-7b-zero-v1.0.json

# Ledger (transparens)
cat ml/ledger/ledger.json
```

### 2. Kontrollera metrics

Kolla efter:
- ‚úÖ `validation_accuracy` > 0.80
- ‚úÖ `fairness_score` > 0.85
- ‚úÖ `ledger_block_id` finns (transparent provenance)

### 3. Testa modellen (n√§r PyTorch √§r installerat)

```python
# Test script
from ml.training.train_language_model import OneSeekTrainer

# Ladda modell
# model = load_model('models/oneseek-7b-zero/weights/oneseek-7b-zero-v1.0.pth')

# Testa med identity-fr√•ga
# response = model.generate("Vem √§r du?")
# print(response)
# Expected: "Jag √§r OpenSeek AI-agent, skapad f√∂r transparens..."
```

## üé® Ut√∂ka Identity Dataset

F√∂r b√§ttre resultat, l√§gg till fler exempel:

### 1. √ñppna dataset-filen

```bash
nano datasets/oneseek_identity_v1.jsonl
# eller
code datasets/oneseek_identity_v1.jsonl
```

### 2. L√§gg till nya exempel

```json
{"instruction": "Hur hanterar du k√§nslig information?", "input": "", "output": "Jag anonymiserar all personlig information och lagrar endast metadata f√∂r transparens..."}
{"instruction": "Vilka √§r dina begr√§nsningar?", "input": "", "output": "Som alla AI-system kan jag g√∂ra misstag. Men min transparens g√∂r det m√∂jligt att uppt√§cka och korrigera dem..."}
```

**Rekommendationer:**
- 100-500 exempel totalt f√∂r robust identity
- T√§ck olika √§mnen: identitet, etik, begr√§nsningar, f√∂rm√•gor
- B√•de svenska och engelska
- Variera fr√•geformuleringen

### 3. Tr√§na om med ut√∂kad dataset

```bash
python scripts/train_identity.py
# Version auto-incrementeras: v1.0 ‚Üí v1.1
```

## üêõ Fels√∂kning

### Problem: "Descriptors cannot be created directly" - Protobuf-fel

**Symptom:**
```
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date...
```

**L√∂sning (ENKLAST):**
```bash
pip install protobuf==3.20.3
```

K√∂r sedan tr√§ningen igen:
```bash
python scripts/train_identity.py
```

**Varf√∂r h√§nder detta?** Nyare versioner av `protobuf` (4.x) √§r inkompatibla med vissa versioner av `sentencepiece` som anv√§nds av tokenizers.

**Alternativa l√∂sningar:**
1. S√§tt milj√∂variabel:
   ```bash
   # Windows PowerShell
   $env:PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION="python"
   python scripts/train_identity.py
   
   # Linux/Mac
   export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
   python scripts/train_identity.py
   ```

2. Uppgradera sentencepiece:
   ```bash
   pip install --upgrade sentencepiece transformers
   ```

### Problem: "Dataset not found"

**L√∂sning:**
```bash
# Verifiera s√∂kv√§g
ls -la datasets/oneseek_identity_v1.jsonl

# Om filen saknas, √•terskapa fr√•n README exempel
cat > datasets/oneseek_identity_v1.jsonl << 'EOF'
{"instruction": "Vem √§r du?", "input": "", "output": "Jag √§r OpenSeek AI-agent..."}
EOF
```

### Problem: "No module named 'transparency_ledger'"

**L√∂sning:**
```bash
# Kontrollera att du k√∂r fr√•n r√§tt directory
cd /path/to/CivicAI
python scripts/train_identity.py

# Eller l√§gg till PYTHONPATH
export PYTHONPATH=$PYTHONPATH:$(pwd)/ml/pipelines
```

### Problem: "Training metrics low"

**L√∂sning:**
- L√§gg till fler exempel (m√•l: 100+)
- K√∂r fler epochs (√§ndra i train_language_model.py)
- Justera learning rate

## üìö N√§sta Steg

### 1. Installera PyTorch f√∂r riktig tr√§ning

```bash
# CPU-version
pip install torch torchvision torchaudio transformers peft protobuf==3.20.3

# GPU-version (CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install transformers peft protobuf==3.20.3
```

**OBS:** Vi anv√§nder `protobuf==3.20.3` f√∂r att s√§kerst√§lla kompatibilitet med `sentencepiece` och tokenizers. Att anv√§nda `protobuf>=4.0` kan orsaka fel vid tokenizer-laddning.

### 2. Ladda ner basmodeller (om du inte redan har dem)

**Om du redan har modeller:**

Skriptet hittar automatiskt modeller i dessa platser:
- `models/mistral-7b-instruct/` (rekommenderad)
- `models/llama-2-7b-chat/` (rekommenderad)
- `models/oneseek-7b-zero/base_models/mistral-7b/`
- `models/oneseek-7b-zero/base_models/llama-2-7b/`

**Om du beh√∂ver ladda ner:**

```bash
# Installera Hugging Face CLI
pip install huggingface_hub

# Ladda ner Mistral 7B (rekommenderad plats)
huggingface-cli download mistralai/Mistral-7B-Instruct-v0.2 \
  --local-dir models/mistral-7b-instruct \
  --local-dir-use-symlinks False

# Ladda ner LLaMA-2 (kr√§ver access request)
huggingface-cli download meta-llama/Llama-2-7b-chat-hf \
  --local-dir models/llama-2-7b-chat \
  --local-dir-use-symlinks False
```

**VIKTIGT:** Anv√§nd `--local-dir-use-symlinks False` f√∂r att undvika symlink-problem p√• Windows.

### 3. K√∂r full tr√§ning med PyTorch

Se huvudguiden: **README.md** ‚Üí "Training OneSeek-7B-Zero: Step-by-Step Guide"

### 4. Testa i dashboard

```bash
# Starta backend
cd backend && npm run dev

# Starta frontend
cd frontend && npm run dev

# √ñppna dashboard
# http://localhost:3000/oqt-dashboard
```

## üìñ Ytterligare Dokumentation

- **README.md** - Komplett 11-stegs guide
- **ONESEEK_7B_ZERO_MIGRATION_GUIDE.md** - Migration fr√•n OQT
- **models/oneseek-7b-zero/MODEL_STORAGE_STRUCTURE.md** - Filformat
- **datasets/oneseek_identity_v1.jsonl** - Komplett identity dataset

## üí° Tips

1. **B√∂rja sm√•tt:** 50 exempel √§r bra f√∂r att l√§ra sig processen
2. **Iterera:** Tr√§na ‚Üí Testa ‚Üí L√§gg till exempel ‚Üí Tr√§na igen
3. **Dokumentera:** Alla tr√§ningsh√§ndelser loggas i ledger
4. **Backup:** Metadata sparas automatiskt i models/
5. **Community:** Bidra med fler identity-exempel till projektet

## ‚ú® Sammanfattning

**Snabbaste v√§gen till tr√§nad modell:**

```bash
# 1. Verifiera dataset
ls datasets/oneseek_identity_v1.jsonl

# 2. K√∂r tr√§ning
python scripts/train_identity.py

# 3. Verifiera resultat
ls models/oneseek-7b-zero/weights/

# 4. Klart! Modellen har l√§rt sig sin identitet.
```

**N√§sta version:** L√§gg till fler exempel och k√∂r `python scripts/train_identity.py` igen!

---

**Fr√•gor?** Se huvuddokumentationen i README.md eller √∂ppna en issue p√• GitHub.
