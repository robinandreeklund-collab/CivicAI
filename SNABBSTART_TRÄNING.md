# Snabbstart: TrÃ¤na OneSeek-7B-Zero med Identity Dataset

Detta dokument ger steg-fÃ¶r-steg instruktioner fÃ¶r att komma igÃ¥ng med att trÃ¤na OneSeek-7B-Zero pÃ¥ identity-dataset sÃ¥ att modellen lÃ¤r sig sin identitet som OpenSeek AI-agent.

## ğŸ¯ MÃ¥l

TrÃ¤na OneSeek-7B-Zero att fÃ¶rstÃ¥:
- Vem den Ã¤r (OpenSeek AI-agent)
- Vad den gÃ¶r (transparent AI-analys med multi-modell konsensus)
- Hur den fungerar (Mistral 7B + LLaMA-2, LoRA/PEFT, ledger-transparens)
- Sina etiska principer (rÃ¤ttvisa, transparens, ansvarsskyldighet)

## ğŸ“‹ FÃ¶rberedelser

### Steg 1: Verifiera att allt Ã¤r installerat

```bash
# Kontrollera att du Ã¤r i rÃ¤tt directory
cd /path/to/CivicAI

# Kontrollera att identity dataset finns
ls -la datasets/oneseek_identity_v1.jsonl

# Output ska visa: 50 rader (exempel) i JSONL-format
```

### Steg 2: Installera Python-beroenden

```bash
# Skapa virtual environment (om du inte redan har ett)
python3 -m venv venv
source venv/bin/activate  # PÃ¥ Windows: venv\Scripts\activate

# Installera beroenden
pip install -r ml/requirements.txt

# Eller installera manuellt:
pip install numpy pandas scikit-learn
```

## ğŸš€ Metod 1: Enkel Snabbstart (Rekommenderad fÃ¶r fÃ¶rsta gÃ¥ngen)

Detta Ã¤r det enklaste sÃ¤ttet att komma igÃ¥ng. Skriptet hanterar allt automatiskt.

### KÃ¶r trÃ¤ningsskriptet:

```bash
# FrÃ¥n repository root
python scripts/train_identity.py
```

**Vad hÃ¤nder:**
1. âœ… Skriptet verifierar att identity dataset finns (50 exempel)
2. ğŸ“¦ Konverterar JSONL till trÃ¤ningsformat
3. ğŸ”„ Delar upp i train/validation (90/10)
4. ğŸ’¾ Sparar till `ml/data/prepared/`
5. ğŸš€ KÃ¶r trÃ¤ningspipeline
6. ğŸ“Š Skapar modellversion med metadata
7. ğŸ“ Loggar till transparency ledger

**Output:**
```
======================================================================
  OneSeek-7B-Zero Identity Training - Quick Start
======================================================================

âœ… Found identity dataset: 50 examples
   Location: datasets/oneseek_identity_v1.jsonl

ğŸ“¦ Preparing training data...
âœ… Training data prepared:
   - Training samples: 45
   - Validation samples: 5

ğŸš€ Starting training...

======================================================================
Training OneSeek-7B-Zero Version 1.0
======================================================================

Dataset sizes:
  Training: 45
  Validation: 5

Training configuration:
  model_name: OneSeek-7B-Zero
  base_models: ['Mistral-7B', 'LLaMA-2']
  use_lora: True
  lora_rank: 8

Training completed!

Final Metrics:
  validation_accuracy: 0.876
  fairness_score: 0.912

âœ… Training completed successfully!
```

## ğŸ”§ Metod 2: Manuell TrÃ¤ning (FÃ¶r avancerade anvÃ¤ndare)

Om du vill ha full kontroll Ã¶ver trÃ¤ningsprocessen:

### Steg 1: FÃ¶rbered dataset

```bash
# Konvertera identity dataset till trÃ¤ningsformat
cd ml/pipelines
python prepare_dataset.py --identity-only
```

### Steg 2: KÃ¶r trÃ¤ning

```bash
cd ml/training
python train_language_model.py --version 1.0
```

### Steg 3: Verifiera resultat

```bash
# Kontrollera att modellfilerna skapades
ls -la models/oneseek-7b-zero/weights/

# Du bÃ¶r se:
# - oneseek-7b-zero-v1.0.json (metadata)
# - oneseek-7b-zero-v1.0.pth (vikter - skapas nÃ¤r PyTorch Ã¤r installerat)
```

## ğŸ“Š Vad hÃ¤nder under trÃ¤ningen?

### 1. Dataset-konvertering

Identity dataset (JSONL):
```json
{
  "instruction": "Vem Ã¤r du?",
  "input": "",
  "output": "Jag Ã¤r OpenSeek AI-agent..."
}
```

Blir till trÃ¤ningsformat:
```json
{
  "id": "identity_0",
  "question": "Vem Ã¤r du?",
  "responses": [{
    "model": "OneSeek-Identity",
    "response_text": "Jag Ã¤r OpenSeek AI-agent..."
  }],
  "analysis": {
    "consensus_score": 1.0
  }
}
```

### 2. TrÃ¤ningsprocessen

```
[Dataset] â†’ [Preprocessing] â†’ [Model Training] â†’ [Validation] â†’ [Save]
   â†“              â†“                   â†“              â†“           â†“
  50           45 train          LoRA/PEFT      Metrics    v1.0.json
examples      5 val              adapters       0.876       v1.0.pth
```

### 3. Resultat som sparas

**Metadata** (`oneseek-7b-zero-v1.0.json`):
```json
{
  "version": "1.0",
  "model_name": "OneSeek-7B-Zero",
  "base_models": ["Mistral-7B", "LLaMA-2"],
  "training_config": {
    "dataset_size": 45,
    "use_lora": true,
    "lora_rank": 8
  },
  "metrics": {
    "validation_accuracy": 0.876,
    "fairness_score": 0.912
  },
  "provenance": {
    "training_data_hash": "sha256:...",
    "ledger_block_id": "block-1",
    "trainer": "OneSeek-Training-Pipeline"
  }
}
```

**Vikter** (`oneseek-7b-zero-v1.0.pth`):
- Skapas nÃ¤r PyTorch Ã¤r installerat
- InnehÃ¥ller LoRA adapter-vikter
- Storlek: ~50-100 MB (LoRA Ã¤r parameter-effektiv!)

## âœ… Verifiera att trÃ¤ningen lyckades

### 1. Kontrollera filer

```bash
# Modellmetadata
cat models/oneseek-7b-zero/weights/oneseek-7b-zero-v1.0.json

# Ledger (transparens)
cat ml/ledger/ledger.json
```

### 2. Kontrollera metrics

Kolla efter:
- âœ… `validation_accuracy` > 0.80
- âœ… `fairness_score` > 0.85
- âœ… `ledger_block_id` finns (transparent provenance)

### 3. Testa modellen (nÃ¤r PyTorch Ã¤r installerat)

```python
# Test script
from ml.training.train_language_model import OneSeekTrainer

# Ladda modell
# model = load_model('models/oneseek-7b-zero/weights/oneseek-7b-zero-v1.0.pth')

# Testa med identity-frÃ¥ga
# response = model.generate("Vem Ã¤r du?")
# print(response)
# Expected: "Jag Ã¤r OpenSeek AI-agent, skapad fÃ¶r transparens..."
```

## ğŸ¨ UtÃ¶ka Identity Dataset

FÃ¶r bÃ¤ttre resultat, lÃ¤gg till fler exempel:

### 1. Ã–ppna dataset-filen

```bash
nano datasets/oneseek_identity_v1.jsonl
# eller
code datasets/oneseek_identity_v1.jsonl
```

### 2. LÃ¤gg till nya exempel

```json
{"instruction": "Hur hanterar du kÃ¤nslig information?", "input": "", "output": "Jag anonymiserar all personlig information och lagrar endast metadata fÃ¶r transparens..."}
{"instruction": "Vilka Ã¤r dina begrÃ¤nsningar?", "input": "", "output": "Som alla AI-system kan jag gÃ¶ra misstag. Men min transparens gÃ¶r det mÃ¶jligt att upptÃ¤cka och korrigera dem..."}
```

**Rekommendationer:**
- 100-500 exempel totalt fÃ¶r robust identity
- TÃ¤ck olika Ã¤mnen: identitet, etik, begrÃ¤nsningar, fÃ¶rmÃ¥gor
- BÃ¥de svenska och engelska
- Variera frÃ¥geformuleringen

### 3. TrÃ¤na om med utÃ¶kad dataset

```bash
python scripts/train_identity.py
# Version auto-incrementeras: v1.0 â†’ v1.1
```

## ğŸ› FelsÃ¶kning

### Problem: "Dataset not found"

**LÃ¶sning:**
```bash
# Verifiera sÃ¶kvÃ¤g
ls -la datasets/oneseek_identity_v1.jsonl

# Om filen saknas, Ã¥terskapa frÃ¥n README exempel
cat > datasets/oneseek_identity_v1.jsonl << 'EOF'
{"instruction": "Vem Ã¤r du?", "input": "", "output": "Jag Ã¤r OpenSeek AI-agent..."}
EOF
```

### Problem: "No module named 'transparency_ledger'"

**LÃ¶sning:**
```bash
# Kontrollera att du kÃ¶r frÃ¥n rÃ¤tt directory
cd /path/to/CivicAI
python scripts/train_identity.py

# Eller lÃ¤gg till PYTHONPATH
export PYTHONPATH=$PYTHONPATH:$(pwd)/ml/pipelines
```

### Problem: "Training metrics low"

**LÃ¶sning:**
- LÃ¤gg till fler exempel (mÃ¥l: 100+)
- KÃ¶r fler epochs (Ã¤ndra i train_language_model.py)
- Justera learning rate

## ğŸ“š NÃ¤sta Steg

### 1. Installera PyTorch fÃ¶r riktig trÃ¤ning

```bash
# CPU-version
pip install torch torchvision torchaudio

# GPU-version (CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 2. Ladda ner basmodeller

```bash
# Mistral 7B och LLaMA-2 (krÃ¤ver ~27 GB)
python scripts/download_models.py
```

### 3. KÃ¶r full trÃ¤ning med PyTorch

Se huvudguiden: **README.md** â†’ "Training OneSeek-7B-Zero: Step-by-Step Guide"

### 4. Testa i dashboard

```bash
# Starta backend
cd backend && npm run dev

# Starta frontend
cd frontend && npm run dev

# Ã–ppna dashboard
# http://localhost:3000/oqt-dashboard
```

## ğŸ“– Ytterligare Dokumentation

- **README.md** - Komplett 11-stegs guide
- **ONESEEK_7B_ZERO_MIGRATION_GUIDE.md** - Migration frÃ¥n OQT
- **models/oneseek-7b-zero/MODEL_STORAGE_STRUCTURE.md** - Filformat
- **datasets/oneseek_identity_v1.jsonl** - Komplett identity dataset

## ğŸ’¡ Tips

1. **BÃ¶rja smÃ¥tt:** 50 exempel Ã¤r bra fÃ¶r att lÃ¤ra sig processen
2. **Iterera:** TrÃ¤na â†’ Testa â†’ LÃ¤gg till exempel â†’ TrÃ¤na igen
3. **Dokumentera:** Alla trÃ¤ningshÃ¤ndelser loggas i ledger
4. **Backup:** Metadata sparas automatiskt i models/
5. **Community:** Bidra med fler identity-exempel till projektet

## âœ¨ Sammanfattning

**Snabbaste vÃ¤gen till trÃ¤nad modell:**

```bash
# 1. Verifiera dataset
ls datasets/oneseek_identity_v1.jsonl

# 2. KÃ¶r trÃ¤ning
python scripts/train_identity.py

# 3. Verifiera resultat
ls models/oneseek-7b-zero/weights/

# 4. Klart! Modellen har lÃ¤rt sig sin identitet.
```

**NÃ¤sta version:** LÃ¤gg till fler exempel och kÃ¶r `python scripts/train_identity.py` igen!

---

**FrÃ¥gor?** Se huvuddokumentationen i README.md eller Ã¶ppna en issue pÃ¥ GitHub.
